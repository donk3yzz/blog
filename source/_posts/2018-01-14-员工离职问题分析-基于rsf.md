---
title: 企业员工离职问题分析——基于RSF方法
author: ''
date: '2018-01-14'
slug: 员工离职问题分析-基于rsf
categories: []
tags:
  - RSF
  - diagrams
---


这篇真的是攒了好久了

## 前言

一时不知从何说起。。

简单解释一下吧，生存分析起源于Daniel Bernoulli对于接种天花风险的研究，经过不断的改进后拥有了处理删失数据的能力；而time-to-event 模型中，自变量是时间、协变量是影响该事件发生的各种因素，而多数情况下我们更关注协变量对于事件发生的影响。生存分析目前被广泛的应用于生物和医疗统计、工程、保险、市场营销等领域。

随机生存森林方法(Random Survival Forest, 下面简称RSF)方法是在随机森林分类方法的基础上，对协变量进行分类的。在一个多分类模型系统 , 随机森林系统的最终分类结果采用简单多数投票法，而RSF是在最后利用Harrel's C Index 或者logrank统计量来衡量生存结局的差异。

至于RSF方法的优势，大致就可以分为两类，一类是生存分析模型的优势，一类是随机森林的优势。RSF方法的第一类优势就在于可以建立time-to-event模型，也拥有了处理删失数据的能力；第二类优势则来源于随机森林方法对于高维数据的处理能力。

其实我在写生存分析论文的时候是很典型的带着方法找问题，为了RSF方法的优势在“高纬”、“大数据量”、“生存分析”、“实证研究”等标签下苦苦寻觅，最后只剩下一点感想就是，time-to-event的模型的适用范围真的比想象中小很多，加上协变量不依赖于时间的要求，剩下能发挥的领域真的简直是不能更窄，想在经济领域运用的话大概只有员工离职问题、用户退订问题和企业寿命问题比较好下手。。

所以我就找到了这份数据，来源于kaggle:[IBM HR Analytics Employee Attrition & Performance
](https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset)
，是IBM数据科学家做的一份人力资源的虚拟数据，其中包括30多个变量和1470个观测值。RSF可能不是处理这个问题最好的方法，这个页面下下有显然有预测精度更高的基于随机森林或者XGboost的处理，然而我只能用RSF。。但是文章都要写了我好歹也得夸一下是不，RSF算法处理员工离职问题的主要优势有以下几条：

+ 员工离职问题是比较符合time-to-event模型
+ 将未离职员工视为删失是一种不错的选择
+ 员工离职的问题的影响因素众多、协变量纬度大
+ 不需要协变量遵循各种假设 e.g.比例风险假设
+ 不需要考虑各协变量间的交互影响

自夸结束，下面是RSF的原理和方法。

## RSF原理与方法

随机生存森林是在随机森林基础上，加入生存分析，采用bootstrap方法从原始数据中有放回的随机抽取`$N_{tree}$`个样本，对每个样本都建立一个二元递归生存树。每个自助样本平均不包含37%的原始数据，将这些数据成为袋外数据（OOB数据），作为RSF的测试样本。最后按照上述方法建立$N_{tree}$棵生存树，并将这些树的结果进行综合。RSF算法可以使用R包`ranger`实现。

假设在树节`$h$`上有`$n_{h}$`例样本，`$(T_{1}, \delta_{1})$`, `$\cdots$`, `$(T_{n}, \delta_{n})$`表示他们的生存时间和截尾信息，`$\delta_i=0$`表示个体`$i$`在时间`$T_i$`时右删失，`$\delta_i=1$`表示在时间`$T_i$`时死亡，则给定的一个变量`$X_j( j=1,2,\cdots,m)$`，在节点`$h$`处可以根据`$X_j<c$`和`$X_j>c$`将生存数据分为两组数据。 RSF在每棵树的节点处，只随机抽取`$M_{try}$`个变量作为分割节点的候选变量，选择使子节点生存差异最大的变量。树节点分裂准则采用Harrell’s C Index分裂方法，或者logrank分裂方法，计算生存函数采用Nelson-Aalen或者Kaplan-Meier估计方法。

## 数据清洗

载入需要的包

```r
library(dplyr)      #数据清洗
library(survival)   #生存函数
library(ggfortify)  #绘制生存函数图
library(ranger)     #实现RSF算法
library(ggalluvial) #绘制桑基图
```



这里应该推荐一下，`dplyr`包用于数据清洗真的是特别好用，提供了一整套的数据清洗流程，其中的`filter`,`select`,`mutate`,`summarize`和`%>%`管道等函数使得数据清洗变得非常易于操作，代码可读性也大大增加，不得不说Hadley实在是改变R语言的男人...

读取数据，并查看数据结构



```r
HR_data <- read.csv(file = "~/GitHub/atheme/source/data/HR-Employee-Attrition.csv", header = T)
```


```r
str(HR_data)
```

```
## 'data.frame':	1470 obs. of  35 variables:
##  $ Age                     : int  41 49 37 33 27 32 59 30 38 36 ...
##  $ Attrition               : Factor w/ 2 levels "No","Yes": 2 1 2 1 1 1 1 1 1 1 ...
##  $ BusinessTravel          : Factor w/ 3 levels "Non-Travel","Travel_Frequently",..: 3 2 3 2 3 2 3 3 2 3 ...
##  $ DailyRate               : int  1102 279 1373 1392 591 1005 1324 1358 216 1299 ...
##  $ Department              : Factor w/ 3 levels "Human Resources",..: 3 2 2 2 2 2 2 2 2 2 ...
##  $ DistanceFromHome        : int  1 8 2 3 2 2 3 24 23 27 ...
##  $ Education               : int  2 1 2 4 1 2 3 1 3 3 ...
##  $ EducationField          : Factor w/ 6 levels "Human Resources",..: 2 2 5 2 4 2 4 2 2 4 ...
##  $ EmployeeCount           : int  1 1 1 1 1 1 1 1 1 1 ...
##  $ EmployeeNumber          : int  1 2 4 5 7 8 10 11 12 13 ...
##  $ EnvironmentSatisfaction : int  2 3 4 4 1 4 3 4 4 3 ...
##  $ Gender                  : Factor w/ 2 levels "Female","Male": 1 2 2 1 2 2 1 2 2 2 ...
##  $ HourlyRate              : int  94 61 92 56 40 79 81 67 44 94 ...
##  $ JobInvolvement          : int  3 2 2 3 3 3 4 3 2 3 ...
##  $ JobLevel                : int  2 2 1 1 1 1 1 1 3 2 ...
##  $ JobRole                 : Factor w/ 9 levels "Healthcare Representative",..: 8 7 3 7 3 3 3 3 5 1 ...
##  $ JobSatisfaction         : int  4 2 3 3 2 4 1 3 3 3 ...
##  $ MaritalStatus           : Factor w/ 3 levels "Divorced","Married",..: 3 2 3 2 2 3 2 1 3 2 ...
##  $ MonthlyIncome           : int  5993 5130 2090 2909 3468 3068 2670 2693 9526 5237 ...
##  $ MonthlyRate             : int  19479 24907 2396 23159 16632 11864 9964 13335 8787 16577 ...
##  $ NumCompaniesWorked      : int  8 1 6 1 9 0 4 1 0 6 ...
##  $ Over18                  : Factor w/ 1 level "Y": 1 1 1 1 1 1 1 1 1 1 ...
##  $ OverTime                : Factor w/ 2 levels "No","Yes": 2 1 2 2 1 1 2 1 1 1 ...
##  $ PercentSalaryHike       : int  11 23 15 11 12 13 20 22 21 13 ...
##  $ PerformanceRating       : int  3 4 3 3 3 3 4 4 4 3 ...
##  $ RelationshipSatisfaction: int  1 4 2 3 4 3 1 2 2 2 ...
##  $ StandardHours           : int  80 80 80 80 80 80 80 80 80 80 ...
##  $ StockOptionLevel        : int  0 1 0 0 1 0 3 1 0 2 ...
##  $ TotalWorkingYears       : int  8 10 7 8 6 8 12 1 10 17 ...
##  $ TrainingTimesLastYear   : int  0 3 3 3 3 2 3 2 2 3 ...
##  $ WorkLifeBalance         : int  1 3 3 3 3 2 2 3 3 2 ...
##  $ YearsAtCompany          : int  6 10 0 8 2 7 1 1 9 7 ...
##  $ YearsInCurrentRole      : int  4 7 0 7 2 7 0 0 7 7 ...
##  $ YearsSinceLastPromotion : int  0 1 0 3 2 3 0 0 1 7 ...
##  $ YearsWithCurrManager    : int  5 7 0 0 2 6 0 0 8 7 ...
```

```r
summary(HR_data)
```

```
##       Age       Attrition            BusinessTravel   DailyRate   
##  Min.   :18.0   No :1233   Non-Travel       : 150   Min.   : 102  
##  1st Qu.:30.0   Yes: 237   Travel_Frequently: 277   1st Qu.: 465  
##  Median :36.0              Travel_Rarely    :1043   Median : 802  
##  Mean   :36.9                                       Mean   : 802  
##  3rd Qu.:43.0                                       3rd Qu.:1157  
##  Max.   :60.0                                       Max.   :1499  
##                                                                   
##                   Department  DistanceFromHome   Education   
##  Human Resources       : 63   Min.   : 1.00    Min.   :1.00  
##  Research & Development:961   1st Qu.: 2.00    1st Qu.:2.00  
##  Sales                 :446   Median : 7.00    Median :3.00  
##                               Mean   : 9.19    Mean   :2.91  
##                               3rd Qu.:14.00    3rd Qu.:4.00  
##                               Max.   :29.00    Max.   :5.00  
##                                                              
##           EducationField EmployeeCount EmployeeNumber
##  Human Resources : 27    Min.   :1     Min.   :   1  
##  Life Sciences   :606    1st Qu.:1     1st Qu.: 491  
##  Marketing       :159    Median :1     Median :1020  
##  Medical         :464    Mean   :1     Mean   :1025  
##  Other           : 82    3rd Qu.:1     3rd Qu.:1556  
##  Technical Degree:132    Max.   :1     Max.   :2068  
##                                                      
##  EnvironmentSatisfaction    Gender      HourlyRate    JobInvolvement
##  Min.   :1.00            Female:588   Min.   : 30.0   Min.   :1.00  
##  1st Qu.:2.00            Male  :882   1st Qu.: 48.0   1st Qu.:2.00  
##  Median :3.00                         Median : 66.0   Median :3.00  
##  Mean   :2.72                         Mean   : 65.9   Mean   :2.73  
##  3rd Qu.:4.00                         3rd Qu.: 83.8   3rd Qu.:3.00  
##  Max.   :4.00                         Max.   :100.0   Max.   :4.00  
##                                                                     
##     JobLevel                         JobRole    JobSatisfaction
##  Min.   :1.00   Sales Executive          :326   Min.   :1.00   
##  1st Qu.:1.00   Research Scientist       :292   1st Qu.:2.00   
##  Median :2.00   Laboratory Technician    :259   Median :3.00   
##  Mean   :2.06   Manufacturing Director   :145   Mean   :2.73   
##  3rd Qu.:3.00   Healthcare Representative:131   3rd Qu.:4.00   
##  Max.   :5.00   Manager                  :102   Max.   :4.00   
##                 (Other)                  :215                  
##   MaritalStatus MonthlyIncome    MonthlyRate    NumCompaniesWorked
##  Divorced:327   Min.   : 1009   Min.   : 2094   Min.   :0.00      
##  Married :673   1st Qu.: 2911   1st Qu.: 8047   1st Qu.:1.00      
##  Single  :470   Median : 4919   Median :14236   Median :2.00      
##                 Mean   : 6503   Mean   :14313   Mean   :2.69      
##                 3rd Qu.: 8379   3rd Qu.:20462   3rd Qu.:4.00      
##                 Max.   :19999   Max.   :26999   Max.   :9.00      
##                                                                   
##  Over18   OverTime   PercentSalaryHike PerformanceRating
##  Y:1470   No :1054   Min.   :11.0      Min.   :3.00     
##           Yes: 416   1st Qu.:12.0      1st Qu.:3.00     
##                      Median :14.0      Median :3.00     
##                      Mean   :15.2      Mean   :3.15     
##                      3rd Qu.:18.0      3rd Qu.:3.00     
##                      Max.   :25.0      Max.   :4.00     
##                                                         
##  RelationshipSatisfaction StandardHours StockOptionLevel
##  Min.   :1.00             Min.   :80    Min.   :0.000   
##  1st Qu.:2.00             1st Qu.:80    1st Qu.:0.000   
##  Median :3.00             Median :80    Median :1.000   
##  Mean   :2.71             Mean   :80    Mean   :0.794   
##  3rd Qu.:4.00             3rd Qu.:80    3rd Qu.:1.000   
##  Max.   :4.00             Max.   :80    Max.   :3.000   
##                                                         
##  TotalWorkingYears TrainingTimesLastYear WorkLifeBalance
##  Min.   : 0.0      Min.   :0.0           Min.   :1.00   
##  1st Qu.: 6.0      1st Qu.:2.0           1st Qu.:2.00   
##  Median :10.0      Median :3.0           Median :3.00   
##  Mean   :11.3      Mean   :2.8           Mean   :2.76   
##  3rd Qu.:15.0      3rd Qu.:3.0           3rd Qu.:3.00   
##  Max.   :40.0      Max.   :6.0           Max.   :4.00   
##                                                         
##  YearsAtCompany  YearsInCurrentRole YearsSinceLastPromotion
##  Min.   : 0.00   Min.   : 0.00      Min.   : 0.00          
##  1st Qu.: 3.00   1st Qu.: 2.00      1st Qu.: 0.00          
##  Median : 5.00   Median : 3.00      Median : 1.00          
##  Mean   : 7.01   Mean   : 4.23      Mean   : 2.19          
##  3rd Qu.: 9.00   3rd Qu.: 7.00      3rd Qu.: 3.00          
##  Max.   :40.00   Max.   :18.00      Max.   :15.00          
##                                                            
##  YearsWithCurrManager
##  Min.   : 0.00       
##  1st Qu.: 2.00       
##  Median : 3.00       
##  Mean   : 4.12       
##  3rd Qu.: 7.00       
##  Max.   :17.00       
## 
```

首先我们需要关注的两个变量`Attrition`和`YearsAtCompany`是我们在构建生存对象时要用到的event和time，需要将他们调整到正确的形式；

其次，这个数据集中存在着很多分类变量如Eduction,JobLevel等，是用阿拉伯数字1,2,3,4,5表示等级的（但不会大于5），但是其变量类型为int，需要调整为factor，否则无法建立模型；

另外变量中存在着一些无效变量和一部分明显依赖于时间的协变量，需要删除；

还有一些比较重要的依赖于时间的变量如`Age`,`MonthlyIncom`需要调整进行归类处理。

可以判断，如果一个int型变量的所有数据都小于5，则该变量的正确类型应该为factor，可以自编函数`ifgt5()`进行判断并利用`mutate_if()`对变量类型进行转换。


```r
ifgt5 <- function(x) {
  if (is.factor(x)) {
    return(F)
  }
  else if (any(x > 5)) {
    return(F)
  }
  else {
    return(T)
  }
}
```


```r
HR_data <- HR_data %>%
  #对time和event进行处理
  mutate(time = YearsAtCompany,
         Attrition = ifelse(Attrition == "Yes", 1, 0)) %>%
  #删除无效变量和明显依赖于时间的变量
  select(-Over18,-StandardHours,
         -(YearsAtCompany:YearsWithCurrManager),
         -TotalWorkingYears) %>%
  #将全部数值小于等于5的int型变量转换为factor型
  mutate_if(a, factor)
```

对`Age`,`salary`等变量进行分层处理

```r
hr_data <- HR_data %>%
  mutate(Age = ifelse((Age<=30), "youth",
                ifelse((Age<=40), "prime",
                ifelse((Age<=50), "middle", "old"))),
         salary = ifelse(MonthlyIncome<4000, "low",
                  ifelse(MonthlyIncome<8000, "medium",
                  ifelse(MonthlyIncome<12000, "high", "rich")))) %>%
  select(-MonthlyIncome)
```


## 建立RSF模型

完成了数据清洗之后，我们就可以对问题建立RSF模型

首先建立生存对象和模型所需的formula。

这里有一个问题是之前没有遇到过的，一次在模型中加入20多个协变量如果挨个输入建立formula实在是..所以可以利用`paste0()`和数据框的变量名直接建立字符串，然后用`as.formula()`公式化，得到的`fml1`就可以直接用于`ranger()`

```r
#建立生存对象
hr_surv <- Surv(time = hr_data$time, hr_data$Attrition==1)
#建立formula
fml1 <- paste0(c("hr_surv~Age",names(hr_data)[3:27],"salary"),collapse = '+') %>%
  as.formula()
```

## 忙活了这么多终于可以回归了...
用`ranger`进行RSF回归，其中每棵树随机抽取的变量数$M_{try}=5$，计算VIMP值的方法采用permutation置换，分裂准则采用Harrel's C Index。

```r
r_fit <- ranger(
  formula = fml1,
  data = hr_data,
  mtry = 5,
  importance = "permutation",
  splitrule = "C",
  verbose = TRUE
)
```
RSF方法不能建立出参数的数学模型，但是会对每个观测值都拟合生存曲线，下面我们随机抽取100个拟合生存曲线并用`ggplot`作图。


```r
#提取拟合的生存曲线
death_times <- r_fit$unique.death.times 
surv_prob <- data.frame(r_fit$survival)
```

不过这中间涉及到一个数据表类型的问题，为了方便画图我们需要使用`reshape2::melt()`将数据转化为长型数据，关于数据表类型和之间的优劣处、相互转换，以后会专门写。


```r
surv_prob[sample(1470,100),] %>%
  t %>%
  cbind(., time = death_times) %>%
  `row.names<-`(NULL) %>%
  reshape2::melt(id = "time")%>%
  subset(value < 1) %>%
  ggplot(aes(x = Var1, y = value, color = Var2)) + 
  geom_line()  + theme(legend.position = "none") +
  labs(x = "survival time", y = "prob of being on the job")
```

![plot of chunk unnamed-chunk-10](/figure/posts/2018-01-14-员工离职问题分析-基于rsf/unnamed-chunk-10-1.png)

### Harrell's C Index评价模型

Harrell's C Index（简单介绍在[这里](http://www.statisticshowto.com/c-statistic/)）是在ROC曲线下面积的基础上发展而来，它估计了预测结果与实际观察到的结果相一致的概率，所以也可以作为RSF的分裂标准（[Matthias Schmid,2016](https://ac.els-cdn.com/S0957417416303633/1-s2.0-S0957417416303633-main.pdf?_tid=4bace9c6-f839-11e7-858d-00000aacb35d&acdnat=1515831251_eebdeff11abe217215e7be6940503859)）。一般C值大于0.7就证明这是一个好的模型，大于0.8就说明是一个强模型，如果能答到1就是完美模型了。


```r
1-r_fit$prediction.error
```

```
## [1] 0.7571
```

Harrell' C Index 达到了0.7571，说明这个模型已经具有比较优秀的预测性质了。

### VIMP值

重要性评分(VIMP值)是用来衡量预测变量预测能力的一个评价，可以依据变量的重要性（VIMP）对变量进行筛选， VIMP值越大表明其预测能力越强。不过需要注意的是，VIMP值并不是一个参数或者统计量，，VIMP的大小只是一个相对值。


```r
vi <- data.frame(sort(round(r_fit$variable.importance, 4), decreasing = TRUE))
names(vi) <- "importance"

vi %>%
  mutate(name = rownames(vi)) %>%
  mutate(name = factor(name, 
                       levels = name)) %>%
  ggplot(aes(x = name, y = importance)) +
  geom_bar(stat = "identity") + coord_flip()
```

![plot of chunk unnamed-chunk-12](/figure/posts/2018-01-14-员工离职问题分析-基于rsf/unnamed-chunk-12-1.png)

### 使用桑基图进行解释

使用过cox模型的人应该都会关注模型的解释，在cox模型里会给出某个变量中具体观察值的显著性，使用者可以轻易的判断其中到底哪个水平对于生存的影响更显著。而在RSF方法中，VIMP值只是衡量了该变量在预测中的相对重要程度，不能无法知道变量中是哪个具体水平起影响作用，比如我们就无法判断`JobLevel`中到底是高的职务等级还是低的离职概率更大。（在课程展示里面蹩到我的部分）

于是我开始寻找能够比较直观的展示，于是就找到了桑基图这个载体（本来想用平行坐标(parallel coordinate)图方法但是这个方法对于分类变量的适应能力比较差，如果是连续性变量就可以使用）。使用`ggalluvial`包实现，可以参考[这篇](http://corybrunson.github.io/ggalluvial/articles/ggalluvial.html)。

选取VIMP值排名前五的变量，和`Attrition`一起构建桑基图。

首先需要将数据调整至alluvia格式，还是利用`dplyr`中的分组统计，


```r
hrdata <-hr_data %>%
  select(Attrition, time, rownames(vi)[1:5])

hr <- hrdata %>%
  #按照次序排列工资水平
  mutate(salary = factor(salary, 
                         levels = c("low", "medium", "high", "rich"))) %>%
  group_by(Attrition, OverTime, 
           JobLevel, salary, 
           StockOptionLevel, MaritalStatus) %>%
  summarise(n = n())
```

绘制桑基图，并添加图例坐标。


```r
hr %>%
  ggplot(aes(weight = n, 
           axis7 = Attrition, axis6 = OverTime, 
           axis4 = salary, axis5 = JobLevel,
           axis3 = StockOptionLevel, 
           axis2 = MaritalStatus)) +
  geom_alluvium(aes(fill = Attrition), width = 1/12) +
  geom_stratum(width = 1/12, fill = "black", color = "grey") +
  geom_label(stat = "stratum", label.strata = TRUE) +
  scale_x_continuous(breaks = 1:6,
                     labels = c("MaritalStatus",
                                "StockOptionLevel", "SalaryLevel",
                                 "JobLevel", "overtime", "Attrition")) 
```

![plot of chunk unnamed-chunk-14](/figure/posts/2018-01-14-员工离职问题分析-基于rsf/unnamed-chunk-14-1.png)

然后我们大概就可以假装分析一番了：公司中大量加班者更倾向于离职，而且加班应该是对于员工离职的影响最大的因素；职务水平低的人，其工作往往具有较强的可替代性，所以该员工群的流动率最大，而低薪金水平和股权水平似乎也反映了同样的问题。在离职问题中，工作压力、职务级别、薪金水平等组织因素相较于个人因素往往具有更大的影响力，工作压力越大者越倾向于离职，这基本是其他学者在论文中共同认可的观点，而现在我们以实证的角度给这一观点提供了更具有说明力的证明。

反正这种级别的解释..显然是怎么都能解释出道理的对吧hhhh


## 总结

所以我们来梳理一下这篇文章的方法结构，首先在正确认识模型的前提下对数据进行处理，然后用RSF方法对企业人力资源数据进行回归处理，得到了每个观测值的生存曲线拟合、一个预测模型（暂时没用到）和各变量的VIMP值，利用VIMP值筛选重要变量结合桑基图进一步解释。所以我们主要完成的是一个数据处理+数据降维+绘图解释的过程，中间浪费掉的预测模型会在下一篇捡起来用。

以为在论文的基础上随便写一下就好的，没想到整了一天，复习周作案 真的是打扰了。

如果存在细节方面的疑问，或者哪个部分需要参考文档可以尽管在评论中提出。

感谢阅读。
